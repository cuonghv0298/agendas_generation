{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "import json\n",
    "import time\n",
    "import random \n",
    "\n",
    "def read_json(file_path: str) -> Dict[str, Any]:\n",
    "    with open(file_path, encoding=\"utf8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def sleep_random(min, range):\n",
    "    time.sleep(min + random.random() * range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "config = read_json('../gemini_config10.json')\n",
    "API_KEY = config[\"api_key\"]\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "# result = client.models.embed_content(\n",
    "#         model=\"gemini-embedding-exp-03-07\",\n",
    "#         contents=\"What is the meaning of life?\")\n",
    "\n",
    "# print(result.embeddings[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Recap agenda\n",
    "source_dir = \"../dataset/recap_agenda_title\"\n",
    "transcript_dir = \"../dataset/AMI_MS_Cleaned\"\n",
    "dirs = os.listdir(source_dir)\n",
    "\n",
    "# Prepare data storage\n",
    "data = {\n",
    "    \"Item\": [],\n",
    "    \"Embedding_Vector\": []\n",
    "}\n",
    "\n",
    "for id, item in enumerate(dirs):\n",
    "    try:\n",
    "        path = os.path.join(os.getcwd(), source_dir, item)\n",
    "        jsondict = read_json(path)\n",
    "        agenda = jsondict[\"agenda\"]\n",
    "\n",
    "        result = client.models.embed_content(\n",
    "            model=\"gemini-embedding-exp-03-07\",\n",
    "            contents=agenda)\n",
    "        print(result.embeddings[0].values)\n",
    "\n",
    "        # Store results\n",
    "        data[\"Item\"].append(item)\n",
    "        data[\"Embedding_Vector\"].append(result.embeddings[0].values)\n",
    "        sleep_random(15, 20)\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Define file paths\n",
    "        output_dir = \"example_outputs/gemini\"\n",
    "        os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "        new_output_path = os.path.join(output_dir, f\"embeddings_{id}.csv\")\n",
    "        old_output_path = os.path.join(output_dir, f\"embeddings_{id-1}.csv\") if id > 0 else None\n",
    "\n",
    "        # Save new CSV\n",
    "        df.to_csv(new_output_path, index=False)\n",
    "        print(f\"Embeddings saved to {new_output_path}\")\n",
    "\n",
    "        # Remove old file if it exists and new file was created successfully\n",
    "        if old_output_path and os.path.exists(old_output_path) and os.path.exists(new_output_path):\n",
    "            os.remove(old_output_path)\n",
    "            print(f\"Removed old file: {old_output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error occurred with file: %s\", item)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst few rows of the saved data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Recap agenda\n",
    "source_dir = \"../dataset/recap_agenda_title\"\n",
    "transcript_dir = \"../dataset/AMI_MS_Cleaned\"\n",
    "dirs = os.listdir(source_dir)\n",
    "\n",
    "# Prepare data storage\n",
    "data = {\n",
    "    \"Item\": [],\n",
    "    \"Embedding_Vector\": []\n",
    "}\n",
    "\n",
    "related_docs_dir = f'../dataset/truncated_single_input_agenda'\n",
    "\n",
    "for id, item in enumerate(dirs):\n",
    "    try:\n",
    "        related_docs_path = os.path.join(os.getcwd(), related_docs_dir, item)\n",
    "        related_docs_dict = read_json(related_docs_path)\n",
    "        related_docs = related_docs_dict[\"truncate_shared_docs\"]\n",
    "\n",
    "        result = client.models.embed_content(\n",
    "            model=\"gemini-embedding-exp-03-07\",\n",
    "            contents=related_docs)\n",
    "        print(result.embeddings[0].values)\n",
    "\n",
    "        # Store results\n",
    "        data[\"Item\"].append(item)\n",
    "        data[\"Embedding_Vector\"].append(result.embeddings[0].values)\n",
    "        sleep_random(15, 20)\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Define file paths\n",
    "        output_dir = \"example_outputs/gemini\"\n",
    "        os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "        new_output_path = os.path.join(output_dir, f\"shared_docs_embeddings_{id}.csv\")\n",
    "        old_output_path = os.path.join(output_dir, f\"shared_docs_embeddings_{id-1}.csv\") if id > 0 else None\n",
    "\n",
    "        # Save new CSV\n",
    "        df.to_csv(new_output_path, index=False)\n",
    "        print(f\"Embeddings saved to {new_output_path}\")\n",
    "\n",
    "        # Remove old file if it exists and new file was created successfully\n",
    "        if old_output_path and os.path.exists(old_output_path) and os.path.exists(new_output_path):\n",
    "            os.remove(old_output_path)\n",
    "            print(f\"Removed old file: {old_output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error occurred with file: %s\", item)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst few rows of the saved data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recap_embeddings = recap_agenda_embeddings[\"Item\"]\n",
    "recap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "recap_agenda_embeddings = pd.read_csv(\"example_outputs/gemini/recap_agenda_embeddings.csv\")\n",
    "shared_docs_embeddings = pd.read_csv(\"example_outputs/gemini/shared_docs_embeddings.csv\")\n",
    "transcript_embeddings = pd.read_csv(\"example_outputs/gemini/transcript_embeddings.csv\")\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    # Evaluate the string to a list and convert to numpy array\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Apply conversion to each embedding column\n",
    "recap_embeddings = np.stack(recap_agenda_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "shared_embeddings = np.stack(shared_docs_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "transcript_embeddings = np.stack(transcript_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "\n",
    "# Combine all embeddings for PCA\n",
    "all_embeddings = np.vstack((recap_embeddings, shared_embeddings, transcript_embeddings))\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_embeddings)\n",
    "\n",
    "# Split the results back into their respective groups\n",
    "n_recap = len(recap_embeddings)\n",
    "n_shared = len(shared_embeddings)\n",
    "\n",
    "recap_pca = pca_result[:n_recap]\n",
    "shared_pca = pca_result[n_recap:n_recap + n_shared]\n",
    "transcript_pca = pca_result[n_recap + n_shared:]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(recap_pca[:, 0], recap_pca[:, 1], c='blue', label='Recap Agenda', alpha=0.6)\n",
    "plt.scatter(shared_pca[:, 0], shared_pca[:, 1], c='red', label='Shared Docs', alpha=0.6)\n",
    "plt.scatter(transcript_pca[:, 0], transcript_pca[:, 1], c='green', label='Transcript', alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA Visualization of Embeddings')\n",
    "plt.legend()\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "recap_agenda_embeddings = pd.read_csv(\"example_outputs/gemini/recap_agenda_embeddings.csv\")\n",
    "shared_docs_embeddings = pd.read_csv(\"example_outputs/gemini/shared_docs_embeddings.csv\")\n",
    "transcript_embeddings = pd.read_csv(\"example_outputs/gemini/transcript_embeddings.csv\")\n",
    "\n",
    "# Function to filter items ending with 'a' (before .json)\n",
    "def filter_type_a(df):\n",
    "    # Extract the last character before '.json' and check if it's 'a'\n",
    "    df['Type'] = df['Item'].str.extract(r'(\\w)\\.json$')  # Extracts the character before '.json'\n",
    "    return df[df['Type'] == 'a']\n",
    "\n",
    "# Apply the filter to each dataframe\n",
    "recap_agenda_filtered = filter_type_a(recap_agenda_embeddings)\n",
    "shared_docs_filtered = filter_type_a(shared_docs_embeddings)\n",
    "transcript_filtered = filter_type_a(transcript_embeddings)\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Apply conversion to each filtered embedding column\n",
    "# Check if the filtered dataframe is not empty before stacking\n",
    "recap_embeddings = np.stack(recap_agenda_filtered[\"Embedding_Vector\"].apply(convert_embedding).values) if not recap_agenda_filtered.empty else np.array([])\n",
    "shared_embeddings = np.stack(shared_docs_filtered[\"Embedding_Vector\"].apply(convert_embedding).values) if not shared_docs_filtered.empty else np.array([])\n",
    "transcript_embeddings = np.stack(transcript_filtered[\"Embedding_Vector\"].apply(convert_embedding).values) if not transcript_filtered.empty else np.array([])\n",
    "\n",
    "# Combine all embeddings for PCA (only include non-empty arrays)\n",
    "all_embeddings_list = [emb for emb in [recap_embeddings, shared_embeddings, transcript_embeddings] if emb.size > 0]\n",
    "if not all_embeddings_list:\n",
    "    print(\"No embeddings found after filtering for type 'a'.\")\n",
    "else:\n",
    "    all_embeddings = np.vstack(all_embeddings_list)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(all_embeddings)\n",
    "\n",
    "    # Split the results back into their respective groups\n",
    "    n_recap = len(recap_embeddings) if recap_embeddings.size > 0 else 0\n",
    "    n_shared = len(shared_embeddings) if shared_embeddings.size > 0 else 0\n",
    "\n",
    "    recap_pca = pca_result[:n_recap] if n_recap > 0 else np.array([])\n",
    "    shared_pca = pca_result[n_recap:n_recap + n_shared] if n_shared > 0 else np.array([])\n",
    "    transcript_pca = pca_result[n_recap + n_shared:] if (len(all_embeddings) - n_recap - n_shared) > 0 else np.array([])\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if recap_pca.size > 0:\n",
    "        plt.scatter(recap_pca[:, 0], recap_pca[:, 1], c='blue', label='Recap Agenda (Type a)', alpha=0.6)\n",
    "    if shared_pca.size > 0:\n",
    "        plt.scatter(shared_pca[:, 0], shared_pca[:, 1], c='red', label='Shared Docs (Type a)', alpha=0.6)\n",
    "    if transcript_pca.size > 0:\n",
    "        plt.scatter(transcript_pca[:, 0], transcript_pca[:, 1], c='green', label='Transcript (Type a)', alpha=0.6)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title('PCA Visualization of Embeddings (Type a Only)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Add grid\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Print explained variance ratio\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "recap_agenda_embeddings = pd.read_csv(\"example_outputs/gemini/recap_agenda_embeddings.csv\")\n",
    "shared_docs_embeddings = pd.read_csv(\"example_outputs/gemini/shared_docs_embeddings.csv\")\n",
    "transcript_embeddings = pd.read_csv(\"example_outputs/gemini/transcript_embeddings.csv\")\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Apply conversion to each embedding column\n",
    "recap_embeddings = np.stack(recap_agenda_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "shared_embeddings = np.stack(shared_docs_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "transcript_embeddings = np.stack(transcript_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "\n",
    "# Combine all embeddings for PCA\n",
    "all_embeddings = np.vstack((recap_embeddings, shared_embeddings, transcript_embeddings))\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_embeddings)\n",
    "\n",
    "# Split the results back into their respective groups\n",
    "n_recap = len(recap_embeddings)\n",
    "n_shared = len(shared_embeddings)\n",
    "\n",
    "recap_pca = pca_result[:n_recap]\n",
    "shared_pca = pca_result[n_recap:n_recap + n_shared]\n",
    "transcript_pca = pca_result[n_recap + n_shared:]\n",
    "\n",
    "# Create scatter plot with index labels\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(recap_pca[:, 0], recap_pca[:, 1], c='blue', label='Recap Agenda', alpha=0.6)\n",
    "plt.scatter(shared_pca[:, 0], shared_pca[:, 1], c='red', label='Shared Docs', alpha=0.6)\n",
    "plt.scatter(transcript_pca[:, 0], transcript_pca[:, 1], c='green', label='Transcript', alpha=0.6)\n",
    "\n",
    "# Add index labels\n",
    "for i, (x, y) in enumerate(recap_pca):\n",
    "    plt.annotate(str(i), (x, y), xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.7, color='blue')\n",
    "for i, (x, y) in enumerate(shared_pca):\n",
    "    plt.annotate(str(i), (x, y), xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.7, color='red')\n",
    "for i, (x, y) in enumerate(transcript_pca):\n",
    "    plt.annotate(str(i), (x, y), xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.7, color='green')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA Visualization of Embeddings with Array Index Labels')\n",
    "plt.legend()\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "recap_agenda_embeddings = pd.read_csv(\"example_outputs/gemini/base_agenda_embeddings.csv\")\n",
    "shared_docs_embeddings = pd.read_csv(\"example_outputs/gemini/shared_docs_embeddings.csv\")\n",
    "transcript_embeddings = pd.read_csv(\"example_outputs/gemini/transcript_embeddings.csv\")\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    # Evaluate the string to a list and convert to numpy array\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Apply conversion to each embedding column\n",
    "recap_embeddings = np.stack(recap_agenda_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "shared_embeddings = np.stack(shared_docs_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "transcript_embeddings = np.stack(transcript_embeddings[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "\n",
    "# Combine all embeddings for PCA\n",
    "all_embeddings = np.vstack((recap_embeddings, shared_embeddings, transcript_embeddings))\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_embeddings)\n",
    "\n",
    "# Split the results back into their respective groups\n",
    "n_recap = len(recap_embeddings)\n",
    "n_shared = len(shared_embeddings)\n",
    "\n",
    "recap_pca = pca_result[:n_recap]\n",
    "shared_pca = pca_result[n_recap:n_recap + n_shared]\n",
    "transcript_pca = pca_result[n_recap + n_shared:]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(recap_pca[:, 0], recap_pca[:, 1], c='blue', label='Base Agenda', alpha=0.6)\n",
    "plt.scatter(shared_pca[:, 0], shared_pca[:, 1], c='red', label='Shared Docs', alpha=0.6)\n",
    "plt.scatter(transcript_pca[:, 0], transcript_pca[:, 1], c='green', label='Transcript', alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA Visualization of Embeddings')\n",
    "plt.legend()\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load all the embedding files\n",
    "file_names = [\n",
    "    \"base_agenda_embeddings.csv\",\n",
    "    \"cat_agenda_embeddings.csv\",\n",
    "    \"only_cat_agenda_embeddings.csv\",\n",
    "    \"rag_agenda_embeddings.csv\",\n",
    "    \"rag_cat_agenda_embeddings.csv\",\n",
    "    \"recap_agenda_embeddings.csv\",\n",
    "    \"shared_docs_embeddings.csv\",\n",
    "    \"template_agenda_embeddings.csv\",\n",
    "    \"transcript_embeddings.csv\"\n",
    "]\n",
    "\n",
    "dataframes = {}\n",
    "for file in file_names:\n",
    "    dataframes[file] = pd.read_csv(f\"example_outputs/gemini/{file}\")\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Process each dataframe and store embeddings\n",
    "embeddings_dict = {}\n",
    "for file, df in dataframes.items():\n",
    "    embeddings_dict[file] = np.stack(df[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "\n",
    "# Combine all embeddings for PCA\n",
    "all_embeddings = np.vstack(list(embeddings_dict.values()))\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(all_embeddings)\n",
    "\n",
    "# Split the results back into their respective groups\n",
    "pca_results = {}\n",
    "start_idx = 0\n",
    "for file, embeddings in embeddings_dict.items():\n",
    "    n_samples = len(embeddings)\n",
    "    pca_results[file] = pca_result[start_idx:start_idx + n_samples]\n",
    "    start_idx += n_samples\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black']\n",
    "for (file, pca_data), color in zip(pca_results.items(), colors):\n",
    "    label = file.replace('.csv', '').replace('_embeddings', '')\n",
    "    plt.scatter(pca_data[:, 0], pca_data[:, 1], c=color, label=label, alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA Visualization of All Embeddings')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to prevent legend overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load all the embedding files\n",
    "file_names = [\n",
    "    \"base_agenda_embeddings.csv\",\n",
    "    \"cat_agenda_embeddings.csv\",\n",
    "    \"only_cat_agenda_embeddings.csv\",\n",
    "    \"rag_agenda_embeddings.csv\",\n",
    "    \"rag_cat_agenda_embeddings.csv\",\n",
    "    \"recap_agenda_embeddings.csv\",\n",
    "    \"shared_docs_embeddings.csv\",\n",
    "    \"template_agenda_embeddings.csv\",\n",
    "    \"transcript_embeddings.csv\"\n",
    "]\n",
    "\n",
    "dataframes = {}\n",
    "for file in file_names:\n",
    "    dataframes[file] = pd.read_csv(f\"example_outputs/gemini/{file}\")\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Process each dataframe and store embeddings\n",
    "embeddings_dict = {}\n",
    "for file, df in dataframes.items():\n",
    "    embeddings_dict[file] = np.stack(df[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "\n",
    "# Combine all embeddings for t-SNE\n",
    "all_embeddings = np.vstack(list(embeddings_dict.values()))\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=300)\n",
    "tsne_result = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "# Split the results back into their respective groups\n",
    "tsne_results = {}\n",
    "start_idx = 0\n",
    "for file, embeddings in embeddings_dict.items():\n",
    "    n_samples = len(embeddings)\n",
    "    tsne_results[file] = tsne_result[start_idx:start_idx + n_samples]\n",
    "    start_idx += n_samples\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "colors = ['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black']\n",
    "for (file, tsne_data), color in zip(tsne_results.items(), colors):\n",
    "    label = file.replace('.csv', '').replace('_embeddings', '')\n",
    "    plt.scatter(tsne_data[:, 0], tsne_data[:, 1], c=color, label=label, alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.title('t-SNE Visualization of All Embeddings')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to prevent legend overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print KL divergence (a measure of how well t-SNE preserves the structure)\n",
    "print(f\"KL Divergence: {tsne.kl_divergence_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load all the embedding files\n",
    "file_names = [\n",
    "    \"base_agenda_embeddings.csv\",\n",
    "    \"cat_agenda_embeddings.csv\",\n",
    "    \"only_cat_agenda_embeddings.csv\",\n",
    "    \"rag_agenda_embeddings.csv\",\n",
    "    \"rag_cat_agenda_embeddings.csv\",\n",
    "    \"recap_agenda_embeddings.csv\",\n",
    "    \"shared_docs_embeddings.csv\",\n",
    "    \"template_agenda_embeddings.csv\",\n",
    "    \"transcript_embeddings.csv\"\n",
    "]\n",
    "\n",
    "# Load and filter dataframes for type 'a'\n",
    "dataframes = {}\n",
    "for file in file_names:\n",
    "    df = pd.read_csv(f\"example_outputs/gemini/{file}\")\n",
    "    # Filter for items where the last character before '.json' is 'a'\n",
    "    df['Type'] = df['Item'].str.extract(r'(\\w)\\.json$')  # Extract the character before '.json'\n",
    "    dataframes[file] = df[df['Type'] == 'a']\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Process each dataframe and store embeddings (only for non-empty dataframes)\n",
    "embeddings_dict = {}\n",
    "for file, df in dataframes.items():\n",
    "    if not df.empty:  # Only process if the filtered dataframe has data\n",
    "        embeddings_dict[file] = np.stack(df[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "    else:\n",
    "        embeddings_dict[file] = np.array([])  # Empty array for empty dataframes\n",
    "\n",
    "# Combine all embeddings for t-SNE (only include non-empty arrays)\n",
    "all_embeddings_list = [emb for emb in embeddings_dict.values() if emb.size > 0]\n",
    "if not all_embeddings_list:\n",
    "    print(\"No embeddings found after filtering for type 'a'.\")\n",
    "else:\n",
    "    all_embeddings = np.vstack(all_embeddings_list)\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=300)\n",
    "    tsne_result = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Split the results back into their respective groups\n",
    "    tsne_results = {}\n",
    "    start_idx = 0\n",
    "    for file, embeddings in embeddings_dict.items():\n",
    "        if embeddings.size > 0:  # Only include non-empty embeddings\n",
    "            n_samples = len(embeddings)\n",
    "            tsne_results[file] = tsne_result[start_idx:start_idx + n_samples]\n",
    "            start_idx += n_samples\n",
    "        else:\n",
    "            tsne_results[file] = np.array([])\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'cyan', 'magenta', 'yellow', 'black']\n",
    "    for (file, tsne_data), color in zip(tsne_results.items(), colors):\n",
    "        if tsne_data.size > 0:  # Only plot if there are points to show\n",
    "            label = file.replace('.csv', '').replace('_embeddings', '') + \" (Type a)\"\n",
    "            plt.scatter(tsne_data[:, 0], tsne_data[:, 1], c=color, label=label, alpha=0.6)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.title('t-SNE Visualization of Type a Embeddings')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Add grid\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Adjust layout to prevent legend overlap\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    # Print KL divergence (a measure of how well t-SNE preserves the structure)\n",
    "    print(f\"KL Divergence: {tsne.kl_divergence_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load all the embedding files\n",
    "file_names = [\n",
    "    \"base_agenda_embeddings.csv\",\n",
    "    \"cat_agenda_embeddings.csv\",\n",
    "    \"only_cat_agenda_embeddings.csv\",\n",
    "    \"rag_agenda_embeddings.csv\",\n",
    "    \"rag_cat_agenda_embeddings.csv\",\n",
    "    \"recap_agenda_embeddings.csv\",\n",
    "    \"shared_docs_embeddings.csv\",\n",
    "    \"template_agenda_embeddings.csv\",\n",
    "    \"transcript_embeddings.csv\"\n",
    "]\n",
    "\n",
    "# Load and filter dataframes for type 'a'\n",
    "dataframes = {}\n",
    "for file in file_names:\n",
    "    df = pd.read_csv(f\"example_outputs/gemini/{file}\")\n",
    "    df['Type'] = df['Item'].str.extract(r'(\\w)\\.json$')\n",
    "    dataframes[file] = df[df['Type'] == 'a']\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Process each dataframe and store embeddings\n",
    "embeddings_dict = {}\n",
    "for file, df in dataframes.items():\n",
    "    if not df.empty:\n",
    "        embeddings_dict[file] = np.stack(df[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "    else:\n",
    "        embeddings_dict[file] = np.array([])\n",
    "\n",
    "# Combine all embeddings for t-SNE\n",
    "all_embeddings_list = [emb for emb in embeddings_dict.values() if emb.size > 0]\n",
    "if not all_embeddings_list:\n",
    "    print(\"No embeddings found after filtering for type 'a'.\")\n",
    "else:\n",
    "    all_embeddings = np.vstack(all_embeddings_list)\n",
    "\n",
    "    # Apply t-SNE with 3 components\n",
    "    tsne = TSNE(n_components=3, random_state=42, perplexity=30, max_iter=300)\n",
    "    tsne_result = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Split the results back into their respective groups\n",
    "    tsne_results = {}\n",
    "    start_idx = 0\n",
    "    labels = []\n",
    "    points = []\n",
    "    \n",
    "    for file, embeddings in embeddings_dict.items():\n",
    "        if embeddings.size > 0:\n",
    "            n_samples = len(embeddings)\n",
    "            tsne_results[file] = tsne_result[start_idx:start_idx + n_samples]\n",
    "            labels.extend([file.replace('.csv', '').replace('_embeddings', '')] * n_samples)\n",
    "            points.extend(tsne_result[start_idx:start_idx + n_samples])\n",
    "            start_idx += n_samples\n",
    "        \n",
    "    # Convert to dataframe for Plotly\n",
    "    tsne_df = pd.DataFrame(points, columns=[\"x\", \"y\", \"z\"])\n",
    "    tsne_df[\"label\"] = labels\n",
    "    \n",
    "    # Create 3D scatter plot\n",
    "    fig = px.scatter_3d(tsne_df, x=\"x\", y=\"y\", z=\"z\", color=\"label\", title=\"3D t-SNE Visualization of Type a Embeddings\")\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=40))\n",
    "    \n",
    "    # Show interactive plot\n",
    "    fig.show()\n",
    "    \n",
    "    # Print KL divergence\n",
    "    print(f\"KL Divergence: {tsne.kl_divergence_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show | grep \"nbformat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load all the embedding files\n",
    "file_names = [\n",
    "    \"base_agenda_embeddings.csv\",\n",
    "    \"cat_agenda_embeddings.csv\",\n",
    "    \"only_cat_agenda_embeddings.csv\",\n",
    "    \"rag_agenda_embeddings.csv\",\n",
    "    \"rag_cat_agenda_embeddings.csv\",\n",
    "    \"recap_agenda_embeddings.csv\",\n",
    "    \"shared_docs_embeddings.csv\",\n",
    "    \"template_agenda_embeddings.csv\",\n",
    "    \"transcript_embeddings.csv\"\n",
    "]\n",
    "\n",
    "# Load and filter dataframes for type 'a'\n",
    "dataframes = {}\n",
    "for file in file_names:\n",
    "    df = pd.read_csv(f\"example_outputs/gemini/{file}\")\n",
    "    df['Type'] = df['Item'].str.extract(r'(\\w)\\.json$')\n",
    "    dataframes[file] = df[df['Type'] == 'a']\n",
    "\n",
    "# Convert string representations of embeddings to numpy arrays\n",
    "def convert_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str), dtype=float)\n",
    "\n",
    "# Process each dataframe and store embeddings\n",
    "embeddings_dict = {}\n",
    "for file, df in dataframes.items():\n",
    "    if not df.empty:\n",
    "        embeddings_dict[file] = np.stack(df[\"Embedding_Vector\"].apply(convert_embedding).values)\n",
    "    else:\n",
    "        embeddings_dict[file] = np.array([])\n",
    "\n",
    "# Combine all embeddings for t-SNE\n",
    "all_embeddings_list = [emb for emb in embeddings_dict.values() if emb.size > 0]\n",
    "if not all_embeddings_list:\n",
    "    print(\"No embeddings found after filtering for type 'a'.\")\n",
    "else:\n",
    "    all_embeddings = np.vstack(all_embeddings_list)\n",
    "\n",
    "    # Apply t-SNE with 3 components\n",
    "    tsne = TSNE(n_components=3, random_state=42, perplexity=30, max_iter=300)\n",
    "    tsne_result = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Split the results back into their respective groups\n",
    "    tsne_results = {}\n",
    "    start_idx = 0\n",
    "    labels = []\n",
    "    points = []\n",
    "    \n",
    "    for file, embeddings in embeddings_dict.items():\n",
    "        if embeddings.size > 0:\n",
    "            n_samples = len(embeddings)\n",
    "            tsne_results[file] = tsne_result[start_idx:start_idx + n_samples]\n",
    "            labels.extend([file.replace('.csv', '').replace('_embeddings', '')] * n_samples)\n",
    "            points.extend(tsne_result[start_idx:start_idx + n_samples])\n",
    "            start_idx += n_samples\n",
    "        \n",
    "    # Convert to dataframe for Plotly\n",
    "    tsne_df = pd.DataFrame(points, columns=[\"x\", \"y\", \"z\"])\n",
    "    tsne_df[\"label\"] = labels\n",
    "    \n",
    "    # Create 3D scatter plot\n",
    "    fig = px.scatter_3d(tsne_df, x=\"x\", y=\"y\", z=\"z\", color=\"label\", \n",
    "                         title=\"3D t-SNE Visualization of Type a Embeddings\", \n",
    "                         opacity=0.9)\n",
    "    \n",
    "    # Improve zoom and navigation\n",
    "    fig.update_traces(marker=dict(size=5, opacity=0.9))  # Increase point size further\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='t-SNE Component 1',\n",
    "            yaxis_title='t-SNE Component 2',\n",
    "            zaxis_title='t-SNE Component 3',\n",
    "            camera=dict(eye=dict(x=-1, y=-0.5, z=-1))  # 5x zoom enhancement\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=40)\n",
    "    )\n",
    "    \n",
    "    # Show interactive plot\n",
    "    fig.show()\n",
    "    \n",
    "    # Print KL divergence\n",
    "    print(f\"KL Divergence: {tsne.kl_divergence_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
